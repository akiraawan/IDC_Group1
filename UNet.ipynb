{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import model_builder\n",
    "from data import *\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = CROP_SIZE + (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./ckpt\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_or_restore_model(fold_index:int):\n",
    "    checkpoints = [checkpoint_dir + \"/\" + name for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        checkpoint_name = os.path.basename(latest_checkpoint)\n",
    "        if checkpoint_name == f\"fold_{fold_index+1}\":\n",
    "            print(\"Restoring from\", latest_checkpoint)\n",
    "            return tf.keras.models.load_model(latest_checkpoint)\n",
    "    print(\"Creating a new model\")\n",
    "    model = model_builder(shape=SHAPE)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005, weight_decay=0.02), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "def plot_stats(history, val, model_name):\n",
    "    acc = history.history['categorical_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = val[0]\n",
    "    val_acc = val[1]\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend(loc=0)\n",
    "    plt.savefig(model_name+'_acc.png')\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(epochs, loss, 'r', label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend(loc=0)\n",
    "    plt.savefig(model_name+'_loss.png')\n",
    "    plt.clf()\n",
    "\n",
    "def run_training(epochs=170, batch_size=10):\n",
    "    x, y = tensor_train_data()\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    val_scores = []\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    for fold_index, (train_index, val_index) in enumerate(kf.split(x)):\n",
    "        print(f\"Fold: {fold_index+1}\")\n",
    "        x_train = x[train_index]\n",
    "        x_val = x[val_index]\n",
    "        y_train = y[train_index]\n",
    "        y_val = y[val_index]\n",
    "\n",
    "        with strategy.scope():\n",
    "            model = make_or_restore_model(fold_index)\n",
    "        \n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_dir + f\"/fold_{fold_index+1}\",\n",
    "                save_weights_only=True,\n",
    "                save_freq=10 * len(x_train) // strategy.num_replicas_in_sync\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        history = model.fit(x_train, y_train, epochs=epochs, callbacks=callbacks, batch_size=batch_size, verbose=2)\n",
    "        val = model.evaluate(x_val, y_val, verbose=1)\n",
    "\n",
    "        model_name = \"unet-\"+str(fold_index)\n",
    "        model.save(model_name+\".keras\")\n",
    "\n",
    "        val_scores.append(val)\n",
    "        plot_stats(history, val, model_name)\n",
    "    with open('unet_val.txt', 'a') as file:\n",
    "        file.write(str(val_scores)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "val_scores = []\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "for fold_index, (train_index, val_index) in enumerate(kf.split(x)):\n",
    "    print(f\"Fold: {fold_index+1}\")\n",
    "    x_train = x[train_index]\n",
    "    x_val = x[val_index]\n",
    "    y_train = y[train_index]\n",
    "    y_val = y[val_index]\n",
    "\n",
    "    model = model_builder(shape=SHAPE)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=150, batch_size=20, verbose=2)\n",
    "    val = model.evaluate(x_val, y_val, verbose=1)\n",
    "\n",
    "    val_scores.append(val)\n",
    "    model_name = \"unet-\"+str(fold_index)\n",
    "    model.save(model_name)\n",
    "\n",
    "    acc = history.history['categorical_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = val['val_loss']\n",
    "    val_acc = val['val_categorical_accuracy']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend(loc=0)\n",
    "    plt.savefig(model_name+'_acc.png')\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(epochs, loss, 'r', label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend(loc=0)\n",
    "    plt.savefig(model_name+'_loss.png')\n",
    "    plt.clf()\n",
    "\n",
    "with open('unet_val.txt', 'a') as file:\n",
    "    file.write(str(val_scores)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdecf95bf1678ba96d55e63d4a72649b75b56ba13e5c6b88f0e1c5055395c3c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
